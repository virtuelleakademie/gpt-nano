---
title: "Informationsanlass zu KI/ChatGPT"
author: "Andrew Ellis"
date: last-modified
date-format: "DD MMMM, YYYY"
bibliography: ../bibliography.bib
nocite: |
  @broschinskiGrafikenErklaertFunktioniert2023
format: 
    revealjs:
        theme: default
        # logo: ../assets/robot.png
        # footer: <a href="https://virtuelleakademie.github.io/gpt-nano">üè† GPT is Not An Oracle</a>
        navigation-mode: vertical
        progress: true
        scrollable: true
        slide-number: true
        show-slide-number: all
        controls-layout: bottom-right
        controls-tutorial: true
        preview-links: auto
        chalkboard: true
        from: markdown+emoji
        code-fold: true
        code-summary: "Show code"
        code-tools: true
        menu: 
          sticky: true
          keyboard: true
          autoOpen: true
          width: normal
          numbers: true
          markers: true

# slide-level: 3
# number-sections: true
---

```{r}
#| warning: false
#| message: false
library(knitr)
```


# Here‚Äôs What Happens When Your Lawyer Uses ChatGPT

```{=html}
<iframe width="780" height="500" src="https://simonwillison.net/2023/May/27/lawyer-chatgpt/" title="ChatGPT: US lawyer admits using AI for case research"></iframe>
```

# The Best Prompts For ChatGPT 

The ultimate list

```{=html}
<iframe width="780" height="500" src="https://www.writingbeginner.com/best-prompts-for-chatgpt/" title="Best prompts for ChatGPT"></iframe>
```

# Inhalt {background-color="#d08770"}

1. Was ist k√ºnstliche Intelligenz?
2. Was ist ChatGPT?
3. Wie wurde ChatGPT trainiert?
4. Energieverbrauch, Bias, Ethik
5. Wie "denkt" ChatGPT?
6. ChatGPT in der Hochschule
7. Wissenschaftliches Arbeiten
8. Tool Demos

::: footer
<a href="https://virtuelleakademie.github.io/gpt-nano">üè† KI/GPT in der Hochschule</a>
:::



# Was ist k√ºnstliche Intelligenz? {background-color="#d8dee9"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
1 [2 3 4 5 6]{style="opacity:0.25"}
:::
:::

## Was ist K√ºnstliche Intelligenz?


```{r}
#| fig-cap: "Quelle: [derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215](https://www.derbund.ch/so-funktioniert-kuenstliche-intelligenz-599276436215)"
include_graphics("../assets/images/was-ist-KI.png")
```


::: {.notes}
Speaker notes go here.
:::


## Machine Learning

- Regelbasierte Systeme m√ºssen programmiert werden.
- ML Modelle lernen implizit ohne Regeln explizit einprogrammiert zu bekommen.


- Wichtige Begriffe:
  - __Trainingsdaten:__ Modelle werden mit Daten gef√ºttert, und Parameter des Modells werden so eingestellt, dass das Modell m√∂glichst "gut" ist.
  - __Testdaten:__ Modelle werden anhand anderer Daten getestet.
  - __Supervised learning:__ Aufgabe ist bekannt, z.B. Bilder - klassifizieren.
  - __Unsupervised learning:__ Unbekannte Muster entdecken.
  - __Reinforcement learning:__ Ziel ist vorgegeben, Modell lernt durch Feedback (Belohnung) wie Ziel erreicht werden kann.

> We have to learn the bitter lesson that building in how we think we think does not work in the long run. We should stop trying to find simple ways to think about space, objects, multiple agents, or symmetries . . . instead we should build in only the meta-methods that can find and capture this arbitrary complexity. We want AI agents that can discover like we can, not which contain what we have discovered [@suttonBitterLesson2019].


## Supervised learning

```{r}
knitr::include_graphics("../assets/images/cats-dogs.png")
```
__Bilder von Hunden und Katzen klassifizeren:__ Was sind die Merkmale, die Hunde von Katzen unterscheiden?



## Reinforcement learning

:::: {.columns}

::: {.column width="50%"}
```{r}
knitr::include_graphics("../assets/images/cartpole.gif")
```
:::

::: {.column width="50%"}

```{r}
knitr::include_graphics("../assets/images/RL-agent.png")
```
:::
::::


::: aside
Beispiel f√ºr RL Model: [AlphaGo](https://www.deepmind.com/research/highlighted-research/alphago) ist das erste Computerprogramm, das einen professionellen (menschlichen) [Go](https://de.wikipedia.org/wiki/Go_(Spiel))-Spieler besiegt hat.
:::






# Was ist ChatGPT? {background-color="#d8dee9"}

::: {.absolute top="0" left="100%"}
::: {.sectionhead}
[1]{style="opacity:0.25"} 2 [3 4 5 6]{style="opacity:0.25"}
:::
:::


## Natural Language Processing 

:::: {.columns}
::: {.column width="50%"}

- Speech recognition
- Text-to-speech synthesis
- Machine translation
- Information extraction
- Information retrieval
- Question answering

:::

::: {.column width="50%"}
- Sentiment analysis
  - üòä I love this movie!
  - üòê This movie is ok.
  - üò† This movie is terrible!
  
:::

::::



## Embeddings

## Generative pre-trained transformer
Not trained for single purpose, but for many tasks





# How was ChatGPT trained? {background-color="#88c0d0"}

https://www.assemblyai.com/blog/how-chatgpt-actually-works/

- training
- data
- architecture
- embeddings
- transformers
  
# Energieverbrauch, Bias, Ethik {background-color="#bf616a"}

## Energieverbrauch

- What we do know is that training ChatGPT used 1.287 gigawatt hours, roughly equivalent to the consumption of 120 US homes for a year. Quelle: [Heating up: how much energy does AI use?](https://techhq.com/2023/03/data-center-energy-usage-chatgpt/)

- @pattersonCarbonEmissionsLarge2022 estimated that the original GPT-3 cost 502 tons of CO2 to train. RLHF would add a bit of overhead on that, perhaps on the order of 1% of the original cost.
- Serving: 7 metric tons of CO2 per day at the end of February. Quelle: [How much energy does ChatGPT use?](https://xcorr.net/2023/04/08/how-much-energy-does-chatgpt-use/)
  
- ChatGPT‚Äôs energy use might have peaked in February, with a trillion tokens produced by a server farm. This would have cost 6-figure hosting bills per day and lead to 7 to 15 metric tons of CO2 per day, about the equivalent of 400-800 households in the US. That‚Äôs not nothing, but in the grand scheme of things is fairly modest, especially compared to more profligate uses of computing like cryptocurrency.

## Bias

:::: {.columns}

::: {.column width="50%"}
```{=html}
<iframe width="780" height="500" src="https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/" title="Vorurteile"></iframe>
```
:::

::: {.column width="50%"}

- Da LLMs von Texten lernen, die von Menschen geschrieben wurden, k√∂nnen sie auch Vorurteile lernen.

Quelle: [Hast du Vorurteile?](https://www.societybyte.swiss/2022/12/22/hi-chatgpt-hast-du-vorurteile/)
:::

::::

## Ethik

:::: {.columns}

::: {.column width="50%"}
```{=html}
<iframe width="780" height="500" src="https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/" title="Traumatische Klickarbeit"></iframe>
```
:::

::: {.column width="50%"}
- Auf Grund der grossen Menge von Trainingsdaten, die f√ºr solche Sprachmodelle ben√∂tigt werden, ist eine Qualit√§tskontrolle schwierig.
- Diskriminierende oder beleidigende Aussagen werden von einem Chatbot generiert.
- Solche Antworten k√∂nnen  als unerw√ºnscht markiert werden.
- Toxische Inhalte wie k√∂rperliche und sexuelle Gewalt, Suizide und Tierqu√§lerei, m√ºssen beim Trainieren aus den Antworten gefiltert werden. Dabei mussten angestellte Arbeitskr√§fte f√ºr weniger als 2 Dollar die Stunde teils schockierende Inhalte lesen. 

Quelle: [Traumatische Klickarbeit](https://www.societybyte.swiss/2023/06/07/traumatische-klickarbeit-die-menschen-hinter-chatgpt/)

:::

::::

# How does ChatGPT work? {background-color="#8fbcbb"}

- How does ChatGPT generate text?
- auto-regressive sampling
- prompting
  + also used to generate images [@rameshZeroShotTexttoImageGeneration2021] 
![](../assets/images/yoda.png)
- role-play simulator
- context
- computation per token
  
# What tasks can ChatGPT do? {background-color="#a3be8c"}


- reasoning
- chain-of-though
- can it think?

# ChatGPT vs human thought {background-color="#b48ead"}


# Future of LLMs {background-color="#ebcb8b"}

- use cases for libraries
- knowledge-augmented retrieval
  - text -> embed -> context (as prompt) -> instruct to use prompt
- agents (toolchain)
- LLM as linguistic interface






# References

::: {#refs}
:::
